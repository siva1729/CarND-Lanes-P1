{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "\n",
    "\n",
    "## Reflection\n",
    "\n",
    "### 1. Overview of the imaging pipeline\n",
    "\n",
    " The imaging pipeline consists of the following steps..\n",
    " \n",
    "  For performing different steps of the imaging pipeline, tuning parameters are defined as Global parameters\n",
    "  that would be used during different stages of pipeline as shown below:\n",
    "      - Kernel size for GaussianBlur filter\n",
    "      - Edge-detection threshold values\n",
    "      - Vertices of the polygon to select the mask (region of interest)\n",
    "      - parameters for line-detection as part of Hough transform\n",
    "      - final trace color and thickness\n",
    "      \n",
    " 1. Convert to Gry-scale image:\n",
    "    The first step is to convert the input image(or image part of the video) to a Grayscale image\n",
    "    to detect edges in the images that would help find the lane markings. This was achieved\n",
    "    using the openCV cv2.cvtColor() function\n",
    "    \n",
    " 2. Remove high-frequency noise in the image before edge-detection:\n",
    "    Then Low-Pass filtering(blurring) is applied on the Grayscale image to remove any high-frequency noise\n",
    "    using the cv2.Gaussianblur() function and the kernel size is chosen to be \"3\" (higher value can be chosen, \n",
    "    filtering at image edges should be considered)\n",
    "    \n",
    " 3. Detect edges in the image:\n",
    "    Using Canny edge-detection function (cv2.Canny), edge-detecting is performed and the low/high threshold values\n",
    "    are chosen such that edges are appropriaely deteced for lane thickness in the suggested ratio of 1:3\n",
    " \n",
    " 4. Select the Region of Interest(ROI):\n",
    "    On this Gray-scale image with edges, a mask is applied to select the region that has both the right and left lanes\n",
    "    and the mask is selected in the form of a Trapezoid whose size parameters can be selected as part of tuning parameters\n",
    "    to selec the region of interest\n",
    " \n",
    " 5. Lines-detection using Hough Transform:\n",
    "    Using the ROI image (with edges), apply Hough transform to detect lines in the image. Using the tuning the parameters\n",
    "    for Hough grid(rho/theta) and threshold for min # of votes required for line to be output and other parameters\n",
    "    detects the lines. The min_line_length and max_line_gap parameters needs to be tuned to detect/mark lines in the\n",
    "    images with min length in pixels and max gap between segments\n",
    "    \n",
    " 6. As part of the hough_lines() function, we have draw_lines() function that uses the lines vector output from \n",
    "    Hough transform and traces the lanes on the image. The draw_line() function consists of the following steps\n",
    "    - First we try to detect the line-segements(from lines vector) that are part of the left and right lane markings\n",
    "      using the slope of the line-segments. Only line-segments that are within a given slope range are considered to avoid\n",
    "      the ones with extreme angles. The slope of the line-segements needs to be within min/max thresholds to be considered     \n",
    "      (slope_min_threshold/slope_max_threshold). Also the x-location of these points w.r.t to center of the image is considered\n",
    "      along with the slope.\n",
    "    - Then store the (x,y) points in separate lists that are part of left/right lane markings. It is better to keep track \n",
    "      the list lengths to check for any case where no line-segements are detected to avoid erroroneous cases.\n",
    "      This is done using (2) flags trace_left and trace_right.\n",
    "    - Then using the left and right points from the list, try to fit a line using linear regression (using the function\n",
    "      np.polyfit()) and get the m,b parameters for left an d right lanes\n",
    "    - Considering the ROI, for marking the lanes from bottom of the image to top of the ROI, the x-cordinates of the\n",
    "      lanes are computed using the y-cordinates of the ROI and slope/intercept of the left/right lanes for bottom and top \n",
    "      of the ROI.\n",
    "    - Two lanes are drawn using the cv2.line() function using the bottom/top (x,y) co-ordinates for left and right lanes.\n",
    "\n",
    "\n",
    "### 2. Potential Shortcomings of current pipeline\n",
    "\n",
    "1. If the line-segments are not detected in the image, then we cannot draw the lines. This could be\n",
    "   due to various reasons lighting conditions in the images (image is not bright), noise in the\n",
    "   image, tuning parameters not good enough for lane markings for max_line_length, etc.\n",
    "   \n",
    "2. Chosing a ROI is also not ideal in all cases as it might be valid during turns, curves,..\n",
    "\n",
    "3. Lanes are not always straight (turns, curves,..), so drawing a line is not ideal.\n",
    "\n",
    "\n",
    "\n",
    "### 3. Possible improvements to pipeline\n",
    "\n",
    "1. A lane should ideally (if exists) have markings on left and right and always with more\n",
    "   or less certain width/distance between them. In the algorithm it is better to take advantage of this.\n",
    "   \n",
    "2. Pre-processing of the images before edge-detection to consider color/dynamic range/contrast to make\n",
    "   sure edge-detection is possible for lane markings\n",
    "\n",
    "3. Make use of the lane curve parameters (slope, etc.) from previous images to correct/detect lane markings\n",
    "   in the current image(s).\n",
    "\n",
    "\n",
    "   \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
